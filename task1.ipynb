{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words():\n",
    "    input_filename = \"./input.txt\"\n",
    "    words = []\n",
    "\n",
    "    with open(input_filename, encoding='utf-8') as input_file:\n",
    "        for line in input_file:\n",
    "            words.append(re.findall(r'\\w+', line))\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corp(tag_to_mytag):\n",
    "    corp_filename = \"../dict_opcorpora/dict.opcorpora.xml\"\n",
    "    base_lemmas = defaultdict(lambda: (None, None, None))\n",
    "    lemmas = defaultdict(list)\n",
    "    lemmata_opened = False\n",
    "    links_opened = False\n",
    "\n",
    "    with open(corp_filename, encoding='utf-8') as corp_file:\n",
    "        for line in corp_file:\n",
    "            try:\n",
    "                if lemmata_opened:\n",
    "                    xml_dict = xmltodict.parse(line)\n",
    "                    lemma = xml_dict['lemma']\n",
    "                    g = lemma['l']['g']\n",
    "                    g = g if len(g) == 1 else g[0]\n",
    "                    base_lemmas[lemma['@id']] = (lemma['l']['@t'].lower().replace(\"ё\", \"е\"),\n",
    "                                                 tag_to_mytag[g['@v']],\n",
    "                                                 lemma['@id'])\n",
    "                elif links_opened:\n",
    "                    xml_dict = xmltodict.parse(line)\n",
    "                    link = xml_dict['link']\n",
    "                    base_lemmas[link['@to']] = base_lemmas[link['@from']]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            if \"<lemmata>\" in line:\n",
    "                lemmata_opened = True\n",
    "            if \"</lemmata>\" in line:\n",
    "                lemmata_opened = False\n",
    "            if \"<links>\" in line:\n",
    "                links_opened = True\n",
    "            if \"</links>\" in line:\n",
    "                links_opened = False\n",
    "                break\n",
    "\n",
    "    with open(corp_filename, encoding='utf-8') as corp_file:\n",
    "        for line in corp_file:\n",
    "            try:\n",
    "                if lemmata_opened:\n",
    "                    xml_dict = xmltodict.parse(line)\n",
    "                    lemma = xml_dict['lemma']\n",
    "                    for f in lemma['f']:\n",
    "                        lemmas[f['@t'].lower().replace(\"ё\", \"е\")].append(base_lemmas[lemma['@id']])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            if \"<lemmata>\" in line:\n",
    "                lemmata_opened = True\n",
    "            if \"</lemmata>\" in line:\n",
    "                lemmata_opened = False\n",
    "                break\n",
    "\n",
    "    return base_lemmas, lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_freqs(base_lemmas, tag_to_mytag):\n",
    "    annotated_filename = \"../dict_opcorpora/annot.opcorpora.no_ambig.xml\"\n",
    "    freqs = defaultdict(\n",
    "        lambda: {\"S\": 0, \"A\": 0, \"V\": 0, \"PR\": 0, \"CONJ\": 0, \"ADV\": 0, \"NI\": 0})\n",
    "\n",
    "    with open(annotated_filename, encoding='utf-8') as annotated_file:\n",
    "        xml_dict = xmltodict.parse(annotated_file.read(),\n",
    "                                   force_list={'sentence': True, 'paragraph': True, 'token': True})\n",
    "        for text in xml_dict['annotation']['text']:\n",
    "            if text['paragraphs'] is None:\n",
    "                continue\n",
    "            for paragraph in text['paragraphs']['paragraph']:\n",
    "                for sentence in paragraph['sentence']:\n",
    "                    last_tag = None\n",
    "                    for token in sentence['tokens']['token']:\n",
    "                        lemma = token['tfr']['v']['l']\n",
    "                        g = lemma['g']\n",
    "                        g = g if len(g) == 1 else g[0]\n",
    "                        if g['@v'] == \"PNCT\":\n",
    "                            continue\n",
    "\n",
    "                        if last_tag is None:\n",
    "                            if tag_to_mytag.get(g['@v']) is not None:\n",
    "                                last_tag = tag_to_mytag[g['@v']]\n",
    "                        else:\n",
    "                            if base_lemmas[lemma['@id']][0] is None:\n",
    "                                continue\n",
    "                            lemma_pair = base_lemmas[lemma['@id']]\n",
    "#                             freqs[lemma_pair[2]][last_tag] += 1\n",
    "                            freqs[lemma_pair[2]][lemma_pair[1]] += 1\n",
    "                            last_tag = lemma_pair[1]\n",
    "\n",
    "    return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"./output.txt\"\n",
    "tag_to_mytag = {\n",
    "    \"NOUN\": \"S\", \"ADVB\": \"ADV\", \"ADJF\": \"A\", \"ADJS\": \"A\", \"COMP\": \"A\",\n",
    "    \"VERB\": \"V\", \"INFN\": \"V\", \"PRTF\": \"V\", \"PRTS\": \"V\", \"GRND\": \"V\",\n",
    "    \"CONJ\": \"CONJ\", \"INTJ\": \"ADV\", \"PRCL\": \"ADV\", \"PREP\": \"PR\",\n",
    "    \"PRED\": \"ADV\", \"NUMR\": \"NI\", \"NPRO\": \"NI\", \"NUMB\": \"NI\", \"UNKN\": \"NI\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lemmas, lemmas = read_corp(tag_to_mytag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = read_freqs(base_lemmas, tag_to_mytag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq(freqs, lemmas, word, last_tag):\n",
    "    ans = None\n",
    "    ans_freq = -1\n",
    "    variants = lemmas[word]\n",
    "\n",
    "    if len(variants) == 0:\n",
    "        return word, \"ADV\", 0\n",
    "\n",
    "    for (lemma, tag, id) in variants:\n",
    "#         cur_freq = sum(freqs[id].values()) if last_tag is None else freqs[id][last_tag]\n",
    "        cur_freq = freqs[id][tag]\n",
    "\n",
    "        if cur_freq > ans_freq:\n",
    "            ans_freq = cur_freq\n",
    "            ans = (lemma, tag, id)\n",
    "\n",
    "    return ans if ans is not None else variants[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 6056.23it/s]"
     ]
    }
   ],
   "source": [
    "with open(output_filename, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for line in tqdm(words):\n",
    "        last_tag = None\n",
    "\n",
    "        for word in line:\n",
    "            word_lower = word.lower().replace(\"ё\", \"е\")\n",
    "            lemma, last_tag, _ = most_freq(freqs, lemmas, word_lower, last_tag)\n",
    "            output_file.write(\"%s{%s=%s} \" % (word, lemma, last_tag))\n",
    "\n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
